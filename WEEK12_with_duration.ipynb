{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85417e2d",
   "metadata": {},
   "source": [
    "# Attribute Information:\n",
    "\n",
    "## Input variables:\n",
    "### bank client data:\n",
    "1 - age (numeric)  \n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')  \n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)  \n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')  \n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')  \n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')  \n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')  \n",
    "### related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')  \n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  \n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')  \n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.  \n",
    "### other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  \n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  \n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)  \n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')  \n",
    "### social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)  \n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)  \n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)  \n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)  \n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)  \n",
    "\n",
    "### Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63d826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4f62080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('bank-clean.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "old_df= pd.read_csv('bank-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d683bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge df with duration column\n",
    "df= pd.concat([df, old_df['duration']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b93ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].apply(lambda x : 1 if x=='yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b28dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('y', axis=1)\n",
    "y=df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d12506",
   "metadata": {},
   "source": [
    "# AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6ae3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96660d1",
   "metadata": {},
   "source": [
    "## Orignal unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3953bd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     13175\n",
      "           1       0.44      0.47      0.46      1745\n",
      "\n",
      "    accuracy                           0.87     14920\n",
      "   macro avg       0.69      0.70      0.69     14920\n",
      "weighted avg       0.87      0.87      0.87     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12154  1021]\n",
      " [  929   816]]\n",
      "--------------------------------------\n",
      "0.8693029490616622\n"
     ]
    }
   ],
   "source": [
    "# Using DecisionTreeClassifier\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "717931b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     13175\n",
      "           1       0.64      0.34      0.44      1745\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.78      0.66      0.69     14920\n",
      "weighted avg       0.88      0.90      0.89     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12837   338]\n",
      " [ 1155   590]]\n",
      "--------------------------------------\n",
      "0.8999329758713137\n"
     ]
    }
   ],
   "source": [
    "# Using Logistec regresion\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b5a230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     13175\n",
      "           1       0.57      0.34      0.43      1745\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.74      0.65      0.68     14920\n",
      "weighted avg       0.88      0.89      0.88     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12728   447]\n",
      " [ 1151   594]]\n",
      "--------------------------------------\n",
      "0.8928954423592493\n"
     ]
    }
   ],
   "source": [
    "# Using KNN\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', KNeighborsClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a051ddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     13175\n",
      "           1       0.63      0.40      0.49      1745\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.78      0.69      0.72     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12770   405]\n",
      " [ 1044   701]]\n",
      "--------------------------------------\n",
      "0.902882037533512\n"
     ]
    }
   ],
   "source": [
    "# Using Random forest\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53fa4d",
   "metadata": {},
   "source": [
    "## using upsampling to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6733940a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39922\n",
       "1    39922\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make the ratio between classes 1:1 using upsampling\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['y']==0]\n",
    "df_minority = df[df['y']==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50040aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_upsampled.drop('y', axis=1)\n",
    "y=df_upsampled['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b272df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     13165\n",
      "           1       0.91      1.00      0.95     13184\n",
      "\n",
      "    accuracy                           0.95     26349\n",
      "   macro avg       0.96      0.95      0.95     26349\n",
      "weighted avg       0.96      0.95      0.95     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[11941  1224]\n",
      " [   26 13158]]\n",
      "--------------------------------------\n",
      "0.9525598694447607\n"
     ]
    }
   ],
   "source": [
    "# Using DecisionTreeClassifier\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c364a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82     13165\n",
      "           1       0.83      0.80      0.81     13184\n",
      "\n",
      "    accuracy                           0.82     26349\n",
      "   macro avg       0.82      0.82      0.82     26349\n",
      "weighted avg       0.82      0.82      0.82     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[11007  2158]\n",
      " [ 2651 10533]]\n",
      "--------------------------------------\n",
      "0.8174883297278834\n"
     ]
    }
   ],
   "source": [
    "# Using Logistec regresion\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "befada56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89     13165\n",
      "           1       0.85      0.97      0.90     13184\n",
      "\n",
      "    accuracy                           0.90     26349\n",
      "   macro avg       0.91      0.90      0.90     26349\n",
      "weighted avg       0.91      0.90      0.90     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[10861  2304]\n",
      " [  400 12784]]\n",
      "--------------------------------------\n",
      "0.8973775095829064\n"
     ]
    }
   ],
   "source": [
    "# Using KNN\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', KNeighborsClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cb10b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     13165\n",
      "           1       0.93      1.00      0.97     13184\n",
      "\n",
      "    accuracy                           0.96     26349\n",
      "   macro avg       0.97      0.96      0.96     26349\n",
      "weighted avg       0.97      0.96      0.96     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[12243   922]\n",
      " [   23 13161]]\n",
      "--------------------------------------\n",
      "0.9641352613002391\n"
     ]
    }
   ],
   "source": [
    "# Using Random forest\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e37a9",
   "metadata": {},
   "source": [
    "The performance did not change with the usage of the duration column but still it need to be removed to be able to use the model in real enviremont since the bank want to know if a clint will subscribe before calling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b6c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
