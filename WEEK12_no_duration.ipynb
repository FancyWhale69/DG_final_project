{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85417e2d",
   "metadata": {},
   "source": [
    "# Attribute Information:\n",
    "\n",
    "## Input variables:\n",
    "### bank client data:\n",
    "1 - age (numeric)  \n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')  \n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)  \n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')  \n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')  \n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')  \n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')  \n",
    "### related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')  \n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  \n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')  \n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.  \n",
    "### other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  \n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  \n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)  \n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')  \n",
    "### social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)  \n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)  \n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)  \n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)  \n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)  \n",
    "\n",
    "### Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b63d826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f62080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('bank-clean.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b93ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].apply(lambda x : 1 if x=='yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b28dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('y', axis=1)\n",
    "y=df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d12506",
   "metadata": {},
   "source": [
    "# AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba6ae3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96660d1",
   "metadata": {},
   "source": [
    "## Orignal unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3953bd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93     13175\n",
      "           1       0.45      0.47      0.46      1745\n",
      "\n",
      "    accuracy                           0.87     14920\n",
      "   macro avg       0.69      0.70      0.69     14920\n",
      "weighted avg       0.87      0.87      0.87     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12160  1015]\n",
      " [  918   827]]\n",
      "--------------------------------------\n",
      "0.8704423592493298\n"
     ]
    }
   ],
   "source": [
    "# Using DecisionTreeClassifier\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "717931b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     13175\n",
      "           1       0.64      0.34      0.44      1745\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.78      0.66      0.69     14920\n",
      "weighted avg       0.88      0.90      0.89     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12837   338]\n",
      " [ 1155   590]]\n",
      "--------------------------------------\n",
      "0.8999329758713137\n"
     ]
    }
   ],
   "source": [
    "# Using Logistec regresion\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b5a230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     13175\n",
      "           1       0.59      0.32      0.41      1745\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.75      0.64      0.68     14920\n",
      "weighted avg       0.88      0.89      0.88     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12785   390]\n",
      " [ 1191   554]]\n",
      "--------------------------------------\n",
      "0.8940348525469168\n"
     ]
    }
   ],
   "source": [
    "# Using KNN\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', KNeighborsClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a051ddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95     13175\n",
      "           1       0.64      0.37      0.47      1745\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.78      0.67      0.71     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n",
      "--------------------------------------\n",
      "[[12817   358]\n",
      " [ 1099   646]]\n",
      "--------------------------------------\n",
      "0.9023458445040214\n"
     ]
    }
   ],
   "source": [
    "# Using Random forest\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53fa4d",
   "metadata": {},
   "source": [
    "## using upsampling to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6733940a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39922\n",
       "1    39922\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make the ratio between classes 1:1 using upsampling\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['y']==0]\n",
    "df_minority = df[df['y']==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50040aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_upsampled.drop('y', axis=1)\n",
    "y=df_upsampled['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81b272df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     13165\n",
      "           1       0.92      1.00      0.95     13184\n",
      "\n",
      "    accuracy                           0.95     26349\n",
      "   macro avg       0.96      0.95      0.95     26349\n",
      "weighted avg       0.96      0.95      0.95     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[11954  1211]\n",
      " [   29 13155]]\n",
      "--------------------------------------\n",
      "0.9529393904892026\n"
     ]
    }
   ],
   "source": [
    "# Using DecisionTreeClassifier\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c364a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82     13165\n",
      "           1       0.83      0.80      0.81     13184\n",
      "\n",
      "    accuracy                           0.82     26349\n",
      "   macro avg       0.82      0.82      0.82     26349\n",
      "weighted avg       0.82      0.82      0.82     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[11007  2158]\n",
      " [ 2651 10533]]\n",
      "--------------------------------------\n",
      "0.8174883297278834\n"
     ]
    }
   ],
   "source": [
    "# Using Logistec regresion\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "befada56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.89     13165\n",
      "           1       0.85      0.97      0.90     13184\n",
      "\n",
      "    accuracy                           0.89     26349\n",
      "   macro avg       0.90      0.89      0.89     26349\n",
      "weighted avg       0.90      0.89      0.89     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[10845  2320]\n",
      " [  448 12736]]\n",
      "--------------------------------------\n",
      "0.8949485748984781\n"
     ]
    }
   ],
   "source": [
    "# Using KNN\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', KNeighborsClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cb10b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     13165\n",
      "           1       0.93      1.00      0.97     13184\n",
      "\n",
      "    accuracy                           0.96     26349\n",
      "   macro avg       0.97      0.96      0.96     26349\n",
      "weighted avg       0.97      0.96      0.96     26349\n",
      "\n",
      "--------------------------------------\n",
      "[[12249   916]\n",
      " [   18 13166]]\n",
      "--------------------------------------\n",
      "0.9645527344491251\n"
     ]
    }
   ],
   "source": [
    "# Using Random forest\n",
    "pipe=Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "]) \n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred= pipe.predict(x_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('--------------------------------------')\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e37a9",
   "metadata": {},
   "source": [
    "The performance of some ML algorithms were affected positivly and negativly this is due to the nature of how each algorithm assign labels to each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b6c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
